# Spatially resolved mapping of cells associated with human complex traits

[文献地址](https://www.nature.com/articles/s41586-025-08757-x)

这篇发表在《Nature》上的文章提出了一个新的空间转录组学分析方法——**gsMap**，它利用**图神经网络（Graph Neural Network, GNN）**来将空间转录组数据与 GWAS 结果相结合，从而**空间定位与复杂性状（如精神疾病）相关的细胞类型和区域**。我们来一步步拆解这个算法，特别说明图神经网络是如何用的，并用一个生动的类比帮助理解。

---

## 一、gsMap 的算法结构（用简单语言解释）

gsMap 一共分为三个核心步骤：

### Step 1：**图神经网络识别“邻居”**

- 空间转录组数据里，每个 spot（点）是一个小区域里的细胞或细胞群，它有两个特征：
  - **基因表达信息**
  - **空间坐标**
- gsMap 把这些 spot 看成图中的节点，并用图神经网络（GNN）学习它们之间的关系。
- 然后，对于每一个 spot，它会找出**在表达和位置上都相似的邻居**，形成一个小团体（microdomain），计算每个基因在这个 spot 的**特异性得分（GSS）**。

### Step 2：**把 GSS 和 SNP 联系起来**

- 把每个 spot 的 GSS 分数映射到跟基因相关的 SNP 上（±50kb），建立 SNP 注释集。
- 然后通过一种叫做**分层 LD score 回归（S-LDSC）**的方法，看这些 SNP 是否富集了某个性状的遗传效应。

### Step 3：**区域层面的关联检测**

- 对于一整个空间区域，gsMap 通过**Cauchy 组合检验**把多个 spot 的 P 值整合起来，判断这个区域和性状的总体关联程度。

---

## 二、图神经网络到底是啥？用比喻来理解

### 想象你在一座城市里找“谁最有可能是艺术家”：

你手上有城市的地图和每个人的兴趣标签。你知道“喜欢画画、常去博物馆、住在艺术区”这些信息都可能和“艺术家”有关。

你不能只看某一个人的兴趣（就像 scRNA-seq 只看基因表达），你还要考虑：

- 这个人住在哪？
- 他周围的人也都爱画画吗？
- 他附近有没有艺术中心？
- 他是不是跟很多艺术爱好者相邻？

这时候你就需要一个**聪明的“城市网络分析器”**来帮你把这些人连成网络，并自动找出：

> “在兴趣和地理位置都相似的小群体中，谁最有可能是艺术家。”

这个“分析器”就是**图神经网络**。

---

## 三、在这篇论文中 GNN 是怎么起作用的？

在 gsMap 中：

- 每个 spot 是一个节点；
- 相邻的 spot 有边连接；
- 图神经网络根据这些连接，学习每个 spot 在表达和空间结构下的“嵌入向量”（embedding）；
- 然后，gsMap 找出每个 spot 的“相似邻居群”，在这个小群体里计算该 spot 的**基因特异性得分（GSS）**。

这一步的作用是：

> **“去噪+增强局部结构信息”**，让算法更鲁棒，避免技术噪声干扰。

---

## 四、gsMap 相比传统方法的优势

传统方法（如 scDRS）只能告诉你“哪些细胞类型”跟某个性状相关，但不知道**它们具体在哪里**。

gsMap 不仅告诉你“是什么细胞”，还告诉你“这些细胞在组织的哪个角落”，就像 GPS 一样，可以：

- 精确地**定位病理相关细胞群**；
- 比如：SCZ（精神分裂症）相关的 Glu 神经元更偏向于 dorsal hippocampus；
- 而 depression（抑郁症）相关的 Glu 神经元则更靠近 medial prefrontal cortex。

---

## 五、总结关键词

- **GNN**：分析图结构数据的神经网络，处理细胞表达+空间坐标。
- **GSS**：基因特异性得分，反映该基因在某个 spot 中是否特别表达。
- **S-LDSC**：通过 GWAS 数据检测富集性。
- **Cauchy Test**：统计上合并多个 P 值判断区域关联。
- **应用场景**：精神疾病、发育生物学、组织病理学等。

---

这个问题问得非常棒！你抓住了关键点：**gsMap 为什么要用 GNN 找 microdomain，而不是直接对每个 spot 打分？**

---

## 🌟 核心问题总结

你在问的其实是：

> 🧠 **“GNN 和基因特异性得分（GSS）的计算之间，到底是什么关系？GNN 找出的 microdomain 有什么价值？”**

---

## ✨ 答案概括

**GNN 的作用不是直接计算 GSS，而是为了更稳健、准确地**  
→ **找到表达模式+空间位置相似的邻居群体（microdomain）**  
→ **再用这些邻居的信息，计算每个 spot 的 GSS（即基因在这个 spot 的特异性表达程度）**

也就是说：

> **GNN → 找 microdomain → 用它来计算 GSS**

---

## 🔍 为什么需要 microdomain？直接算不行吗？

### ✅ 原始问题：

- 空间转录组数据本身**噪声大、稀疏**
- 单个 spot 的表达值有时候不稳定，比如技术误差、低测序深度
- 特别是高分辨率 ST，比如 Stereo-seq，一个 bin 有时只包含 1~3 个细胞，噪声更严重

### ✅ 所以解决思路是：

我们不再**孤立地看某个 spot 的表达值**，而是：

> “找到跟它相似的一群邻居，把这群邻居的表达模式融合起来，给它的表达打分，这样更可靠。”

这个邻居群体，就是所谓的 **microdomain**

---

## 🤖 GNN 在这里怎么起作用？

传统做法可能是：

```python
if distance(spot_i, spot_j) < threshold and expression_similarity > threshold:
    treat as neighbor
```

但这种方法很**手工+规则化**，效果差。

gsMap 用 GNN 的方式是：

1. 把每个 spot 表达值 + 空间坐标 作为节点特征
2. 建立图结构：邻接关系可以是空间邻近（kNN）
3. 用图神经网络学习每个 spot 的**嵌入向量**
4. 对每个 spot，用 cosine similarity 在嵌入空间中找最像的一些邻居，组成 microdomain

这种方法让 GNN 来“自动学习”如何平衡表达信息和空间位置，更加智能、灵活、鲁棒。

---

## 🧮 然后如何计算 GSS？

在 microdomain 选定后，每个 spot 的 GSS 是这样算的（文中说得很清楚）：

\[
GSS\_{i,gene} = \frac{\text{mean(rank_within_microdomain)}}{\text{mean(rank_within_whole_slice)}}
\]

通俗翻译：

- 如果某个基因在该 spot 的表达，在其邻居中是高的（排名靠前）
- 同时相比整个组织切片，它也是高的
- 那这个基因就“特异性表达”在这个 spot 上

GSS 值就高！

---

## ✏️ 类比一下：

### 🧠 假设你想找“城市里最有艺术气息的人”

你不能只看他一个人的爱好（太噪了），而是：

1. 找出跟他生活方式相似的邻居群（microdomain）
2. 看他在这个群体中是否更突出地爱艺术
3. 再对比整个城市的水平
4. 如果他在邻居中和城市里都最爱艺术，那他就是“艺术气息强”的人

→ 所以，**microdomain 是“局部参考背景”**，而不是计算噪声大的单点数据。

---

## ✅ 小结

| 内容        | 用处                                            |
| ----------- | ----------------------------------------------- |
| GNN         | 从表达+空间信息中学习“spot 之间的结构”          |
| microdomain | 每个 spot 的“相似邻居群”，帮助抗噪声            |
| GSS         | 基于 microdomain 和全局表达计算的相对特异性打分 |

---

我可以下一步帮你实现一个 toy 例子：  
给一个简化版 ST 数据，用 GNN 找 microdomain，并计算 GSS，看看加不加 microdomain 对结果差多少。

你想试一下这个案例，还是先继续深入 GNN 本身的机制？

好问题！`GSS`（Gene Specificity Score）在这篇文章中是**作者根据分析目标设计的一种新的特异性打分方法**，并不是一个已有的“标准”算法或已有命名广泛传播的方法。

不过，它背后的思想与一些常见的生物信息学打分方法（比如 AUCell、rank-based enrichment 等）**非常相似**。我们可以把它理解为一个“**相对表达特异性打分法**”，它的设计充分考虑了以下几点：

---

## 🧠 一、GSS 是什么？

GSS（Gene Specificity Score），在 gsMap 中用于衡量：

> **某个基因在某个 spot 是否“局部”且“相对整体”地特异性表达**

通俗来说：

- 如果一个基因在某个 spot 的表达**在这个 spot 的邻居（microdomain）中很高**
- 并且**在整个切片中的平均排名也较高**
- 那它就很“特异性”地表达在这个 spot 上，说明这个 spot 可能是这个基因活跃区域

---

## 📐 二、GSS 的计算公式

文中描述如下：

\[
GSS*{i,g} = \frac{R*{i,g}^{\text{(micro)}}}{R\_{g}^{\text{(global)}}}
\]

其中：

- \( R\_{i,g}^{\text{(micro)}} \)：基因 \(g\) 在 spot \(i\) 的 microdomain 中的平均表达排名（越靠前越好）
- \( R\_{g}^{\text{(global)}} \)：该基因在整个切片中所有 spot 的平均排名

注意这里的表达值是做了**排序 rank**处理的，不是直接用原始 counts，这样更稳健，抗噪声能力更强。

---

## 🔍 三、GSS 是已有算法吗？

### ✅ GSS 本身不是一个已有命名的“标准算法”

它是 **gsMap 中专门设计的一种 gene-level score**，用于结合空间邻域（microdomain）表达进行打分的工具。

### ✅ 但它的设计思想有参考以下几类经典方法：

| 方法                                   | 类似点                            | 不同点                               |
| -------------------------------------- | --------------------------------- | ------------------------------------ |
| **AUCell**                             | 用 gene rank 评估表达是否特异性高 | AUCell 更适合 gene set 而不是单基因  |
| **Z-score-based specificity**          | 用表达值与平均值比较              | 没有 rank 和空间信息参与             |
| **SCMarker / SEACells 等局部聚合方法** | 先聚邻居再计算                    | 不同在于这些多用于聚类或 marker 选取 |
| **PageRank-based gene scores**         | 图上信息传播与排名                | 更依赖网络传播而不是局部排名         |

---

## 🧪 四、GSS 的优点

1. **抗噪声**：利用邻居表达（microdomain），不是单点表达
2. **排序稳健**：使用 rank 而不是 raw count，可以缓解 drop-out 等问题
3. **对空间敏感**：引入 GNN 得到的邻居，融合表达+空间信息

---

## 📊 五、为什么不用传统的特异性指标（如 tau score、entropy）？

因为那些指标（例如 tau）适合在 bulk RNA-seq 或 scRNA-seq 下比较多个 cell type 的基因表达，而**没有考虑空间分布特性和技术噪声问题**。

在空间转录组中，使用微邻域（microdomain）+ rank 是一种更**鲁棒且局部敏感**的方式，更适合 gsMap 这样需要对“某个点”的特异性表达做出判断的场景。

---

## ✅ 小结

| 问题               | 答案                                                   |
| ------------------ | ------------------------------------------------------ |
| GSS 是现成算法吗？ | ❌ 不是标准算法，是作者为 gsMap 设计的特异性评分机制   |
| 类似哪些方法？     | 类似于 AUCell、局部聚合表达打分、rank-based enrichment |
| 核心亮点           | 融合表达+空间的鲁棒特异性打分，适合 ST 数据抗噪分析    |

---

如果你想的话，我可以帮你实现一个 Python 小脚本，用 GSS 算法来对一个 toy spatial transcriptomics 数据集进行打分，方便你亲手试试。需要我安排一下吗？

你继续追问得非常到位，咱们把这个问题拆成两部分来聊：

---

### 🎯 你问的核心是两个问题：

1. **什么是 cosine similarity？它在 GNN 里起了什么作用？**
2. **如果 GNN 是无监督的，那它怎么知道“我分的好不好”？有没有反馈机制？**

我们先说第一个。

---

## 1️⃣ 什么是 Cosine Similarity？它在 GNN 里干嘛用的？

### 📐 定义（数学）：

cosine similarity 是两个向量的夹角余弦：

\[
\text{cosine_sim}(A, B) = \frac{A \cdot B}{\|A\| \cdot \|B\|}
\]

其中：

- \( A \cdot B \) 是向量点积
- \( \|A\| \) 是向量的模长

这个值 ∈ [-1, 1]，含义是：

- 越接近 **1**：两个向量越“方向一致” → 越相似
- 越接近 **0**：越不相关
- 越接近 **-1**：方向相反

---

### 💡 在 GNN 中的作用：

在这篇 gsMap 论文里：

- GNN 输出了每个 spot 的嵌入向量 \( Z_i \)
- 然后作者用 **cosine similarity** 来判断两个 spot 是否“相似”
- 对于每个 spot，找 cosine 相似度最高的若干个邻居 → microdomain

**→ 它是作为“相似性度量工具”来用的，不是优化目标本身**

---

## 2️⃣ GNN 怎么知道“我分得好不好”？有没有评估指标？

现在到了重点！

### ✅ 在无监督 GNN 中，**通常没有 ground truth 标签来告诉你对不对**

所以，评估方式一般是**“间接的”**：

---

### 🚧 在 gsMap 中的思路：

gsMap 的 GNN 没有损失函数，但它的“好坏”通过后续 GSS 的质量间接体现：

> 如果 GNN 产生的嵌入 → 得到的 microdomain 能帮助我们更稳定、准确地计算 GSS → GSS 与 GWAS trait 显著相关 → 那这个 GNN 就“好”

也就是说，它的反馈不是来自 GNN 自己，而是：

📈 “你这 GNN 分出来的邻居群，能不能让后续 GWAS 富集分析更有意义？”

---

### 🎓 类比一下：

你让一群人分组，不告诉他们正确答案，只说：

- “你们分完组后，我会拿去做个后续实验，看看结果准不准”
- 实验结果越成功，说明你们的分组就越靠谱

GNN 在这里扮演的就是这个“先分组”的角色，而最终评估指标是后面的 GWAS 关联显著性（比如 S-LDSC 的 P 值）。

---

## 🧪 那有没有办法“让 GNN 本身知道自己好不好”？

可以有，这就是 **自监督 GNN 的研究方向**。常见策略包括：

### ✅ Graph Contrastive Learning

- 构造“正样本”和“负样本”（比如相邻的点 vs 不相邻的点）
- 希望 GNN 输出：
  - 正样本距离小（高 cosine）
  - 负样本距离大（低 cosine）
- Loss 函数：`InfoNCE` 或 `TripletLoss`，可训练！

这样 GNN 就可以通过 loss 直接优化“相似点更靠近”的目标。

---

## ✅ 小结一下

| 问题                       | 答案                                     |
| -------------------------- | ---------------------------------------- |
| cosine similarity 是啥？   | 两个向量夹角的相似性，越接近 1 越相似    |
| 在 gsMap 中怎么用？        | 比较 spot embedding 的相似性，用于选邻居 |
| GNN 知道自己分得好不好吗？ | ❌ 不直接知道，依靠后续 GSS 的效果体现   |
| 能让 GNN 自己知道吗？      | ✅ 可以做自监督 GNN，引入对比学习 loss   |

---

如果你想，我可以写个小例子演示一下：

- 用 GNN 得到 embedding
- 用 cosine similarity 找最相似的点
- 用可视化看效果

也可以进一步介绍“图对比学习”的思想和 loss 设计。你更感兴趣哪个方向？

非常专业的问题！你问的这个**“如何找到邻居边界”**，其实是在追问：

> ✳️ 在图神经网络中（特别像 gsMap 这种无监督的应用场景里），  
> **我怎么判断一个点的哪些邻居应该纳入 microdomain，而哪些不应该？**

也就是：

> “邻居的数量（邻域大小）怎么定？”、“有没有一个合理的边界/距离标准？”

---

## 🧠 简单回答：

在像 **gsMap** 这类基于 GNN 的场景中，**“邻居边界”并不是固定的几何距离或数量，而是基于 learned similarity（比如 cosine similarity）排序后选择的前 K 个邻居。**

---

## 🪄 更详细解释：邻居边界的几种确定方法

### ✅ 方法一：**Top-K 相似度选邻居（gsMap 采用）**

- 每个 spot 经过 GNN 得到一个 embedding 向量 \( Z_i \)
- 然后和所有其他 spot 比较 **cosine similarity**
- **取最相似的前 K 个 spot** 作为它的 microdomain（邻域）

这种方式的“邻居边界”不是一个几何半径，而是一个“相似性排名”的阈值（Top-K）。

#### ➕ 优点：

- 自适应：不受空间密度不均影响
- 可以融合表达 + 空间坐标信息

#### ➖ 缺点：

- K 值选得太小 → 容易过拟合局部噪声
- K 值太大 → 融合太多不相关的 spot，稀释特征

---

### ✅ 方法二：**基于空间距离的 radius 邻居**

- 只用空间坐标，定义一个半径 r
- 所有在这个距离内的点都作为邻居

这种方法更传统，类似构建 kNN 图或 Gaussian kernel。

#### ➕ 直观、与物理距离强相关

#### ➖ 无法结合表达信息，可能忽略“远处但相似”的表达结构

---

### ✅ 方法三：**kNN 图（空间或表达或 joint space）**

- 用 PCA / UMAP / GNN 得到 embedding 空间
- 在这个空间上用 kNN 算法建立图结构（每个点连接最相似的 k 个点）

这可以用在 GNN 输入前，也可以 GNN 后用作选 microdomain。

---

## 🧪 gsMap 实际采用的是哪种？

根据文中描述，gsMap 的做法是这样的：

> **构建一个 GNN，将表达+空间坐标作为输入，得到每个 spot 的嵌入向量**  
> 然后，对每个 spot \( i \)，**用 cosine similarity 找最像的 Top-K 个 spot 作为邻居 → microdomain**

这里的邻居边界由 **相似性排序的前 K 名**决定，不是空间距离或固定半径。

---

## 🧩 你可能还关心：

### ❓K 值怎么选？

文中没明确写死 K，但在 Supplementary Note 中提到了用验证或模拟数据集来选择一个“平衡鲁棒性和特异性”的 K 值（常见如 8~30 之间）

### ❓ 如果 GNN embedding 不好，那邻居是不是也会错？

✅ 是的，这就是 GNN quality 与 GSS 准确度挂钩的地方  
→ 所以在 GNN 中融合空间 + 表达很重要，能增强邻域的“生物一致性”

---

## ✅ 小结表格

| 邻域定义方式                                     | 是否适应表达 | 是否空间相关      | gsMap 是否使用      | 优缺点                       |
| ------------------------------------------------ | ------------ | ----------------- | ------------------- | ---------------------------- |
| Top-K cosine similarity（在 GNN embedding 空间） | ✅ 是        | ✅ 是（通过输入） | ✅ 是               | 自适应表达结构，但需选好 K   |
| 距离半径（spatial）                              | ❌ 否        | ✅ 是             | ❌ 否               | 易受空间密度影响，表达结构差 |
| kNN 图（表达/空间/融合）                         | ✅           | ✅                | 可能用于 GNN 输入前 | 强大但需调参                 |

---

如果你感兴趣，我可以帮你：

1. 实现一个 toy spatial dataset，调 K 值看看邻域变化；
2. 或者演示如何用 GNN 输出 + cosine similarity 找 microdomain；
3. 或者做一个图形化展示邻居边界的例子！

你希望我们怎么继续？💡
